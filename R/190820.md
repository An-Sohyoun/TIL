> day69 배운 내용 :  그래프 파일 저장 | 텍스트 마이닝 | 지도 시각화



## 0. 그래프를 파일로 저장하기

```r
library(ggplot2)
mpg2 <- aggregate(data=mpg, hwy~class,mean)
png("gg.png",width=600,height=500) # 파일정보
ggplot(data=economics,aes(x=date,y=unemploy)) +
  geom_line()
dev.off() # 화면이 아니라 파일로 출력하라는 의미 → 웹에서 요청하자마자 만듦
```



## 1. 텍스트 마이닝

:heavy_check_mark: 문자로 된 데이터에서 가치 있는 정보를 얻어 내는 분석 기법을 '텍스트 마이닝(Text mining)'이라함

### 1-1. 자주 사용된 단어

패키지 설치

```r
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP") 
install.packages("stringr")
```

패키지 로드

```r
library(KoNLP)
library(dplyr)
library(stringr)
```

데이터 불러오기

```R
txt <- readLines("hiphop.txt")
```

텍스트 마이닝

```r
# 특수문자 제거
txt <- str_replace_all(txt,"\\W"," ") 

# 가사에서 명사 추출
nouns <- extractNoun(txt)

# count하여 TABLE 만듦
cnt <- table(unlist(nouns))
df_cnt <- as.data.frame(cnt,stringsAsFactors = F) # DataFrame 형태로 저장
colnames(df_cnt) <- c("word","freq") # 열 이름을 설정 (단어, 빈도수)

# 두 글자 이상 단어 추출
df_word <- filter(df_cnt,nchar(word) >= 2)
# 데이터 정렬
df_word <- df_word[order(df_word$freq,decreasing = T),]
# TOP20 추출
df_word <- head(df_word,20)
```



### 1-2. 워드 클라우드

패키지 설치

```r
install.packages("wordcloud")
```

패키지 로드

```R
library(wordcloud)
library(RColorBrewer)
```

단어 색상 목록 만듦

```r
pal <- brewer.pal(8,"Dark2")
```

난수 고정

```r
set.seed(1234)
```

>  ∴ 동일한 모양의 워드 클라우드 만들어지도록

워드 클라우드 만듦

```r
wordcloud(words = df_word$word, # 단어
          freq = df_word$freq, # 빈도
          min.freq = 2, # 최소 단어 빈도
          max.words = 200, # 표현 단어 수
          random.order = F, # 고빈도 단어 중앙 배치
          rot.per = .1, # 회전 단어 비율
          scale = c(4,0.3), # 단어 크기 범위
          colors = pal) # 색상 목록
```

<br>

:orange: **day69 workshop** : 국정원 트윗 텍스트 마이닝

패키지 준비

```r
library(KoNLP)
library(dplyr)
library(stringr)
library(wordcloud)
library(RColorBrewer)
```

> 이전에 설치를 해서 다시 하지 않아도 됨

변수명 수정

```
twitter <- rename(twitter,
                  no = 번호,
                  id = 계정이름, 
                  date = 작성일,
                  tw = 내용)
```

특수문자 제거

```r
twitter$tw <- str_replace_all(twitter$tw,"\\W"," ")
head(twitter$tw)
```

단어 빈도표 만듦

```r
# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)
# 추출한 명사 list를 문자열 벡터로 변환 & 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
# 변수명 수정
df_word <- rename(df_word,
                  word = Var1,
                  freq = Freq) 
```

```r
# 두 글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)

# 상위 20개 추출
top20 <- df_word %>%
  arrange(desc(freq)) %>%
  head(20)
```

워드클라우드 만듦

```r
pal <- brewer.pal(9,"Blues")[5:9] # 색상 목록 생성
set.seed(1234) # 난수 고정

wordcloud(words = df_word$word, # 단어
          freq = df_word$freq, # 빈도
          min.freq = 10, # 최소 단어 빈도
          max.words = 200, # 표현 단어 수
          random.order = F, # 고빈도 단어 중앙 배치
          rot.per = .1, # 회전 단어 비율
          scale = c(6, 0.2), # 단어 크기 범위
          colors = pal) # 색상 목록
```

<br>

[참고]

```r
wc3 <- function(){
  library(XML);  
  library(KoNLP);
  library(wordcloud);
  library(RColorBrewer);
  library(rvest);
  html1 <- htmlTreeParse(
    "http://hanatour.com",
    useInternalNodes = TRUE,
    trim=TRUE,
    encoding = "EUC-KR"
  );
  
  
  txt1 <- xpathSApply(html1,"//p",xmlValue);
  html2 <- htmlTreeParse(
    "http://modetour.com",
    useInternalNodes = TRUE,
    trim=TRUE,
    encoding = "UTF-8"
  );
  txt2 <- xpathSApply(html2,"//p",xmlValue);
  html3 <- htmlTreeParse(
    "http://www.tourcabin.com",
    useInternalNodes = TRUE,
    trim=TRUE,
    encoding = "UTF-8"
  );
  txt3 <- xpathSApply(html3,"//p",xmlValue);
  
  txt1 <- iconv(txt1,"UTF-8","EUC-KR");
  txt2 <- iconv(txt2,"UTF-8","EUC-KR");
  txt3 <- iconv(txt3,"UTF-8","EUC-KR");
  
  txt <- union(txt1,txt2);
  txt <- union(txt,txt3);
  nouns <- extractNoun(txt)
  
  c <- unlist(nouns);
  c <- as.character(c)
  
  numtxt <- Filter(function(x){ nchar(x) >=2 },c);
  numtxt <- gsub("[0-9]","",numtxt); # gsub을 이용하여 공백과 알파벳 등 대체할 수 있음
  numtxt <- gsub("[A-Z]","",numtxt);
  numtxt <- gsub("[a-z]","",numtxt);
  numtxt <- gsub("\\W","",numtxt);
  write(unlist(numtxt),"text_temp.txt"); # 'text_tmp' 임시 파일로 저장
  numtable <- read.table("text_temp.txt"); # 파일을 테이블로 읽어옴
  wcount <- table(numtable);
  wcount <- head(sort(wcount,decreasing = T),100);
  
  palate <- brewer.pal(9,"Set1");
  jpeg("wc3.jpeg",width = 800, height = 600, quality = 100) # jpeg 파일로 저장
  wordcloud(names(wcount),
            freq=wcount,
            scale=c(5,0,5),
            rot.per=0.35,
            min.freq=1,
            random.order=F,
            random.color=T,
            colors=palate
  );
}
```



## 2. 지도 시각화

```r
library(kormaps2014)
library(ggiraphExtra)
library(ggplot2)
library(dplyr)
library(mapproj)
head(changeCode(korpop1))
str(kormap1)
korpop1 <- rename(korpop1,
                  pop="총인구_명",
                  name="행정구역별_읍면동")
ggChoropleth(data=korpop1, # 지도에 표현할 데이터
            aes(fill=pop, # 색깔로 표현할 변수
                map_id=code, # 지역 기준 변수
                tooltip=name), # 지도 위에 표시할 지역명
            map=kormap1, # 지도 데이터
            interactive = T) # 인터랙티브
```

>  Export > Save as Web Page 에서 HTML 문서로 저장할 수도 있음


